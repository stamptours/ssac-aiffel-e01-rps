{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSAC X AIFFEL AI Course Exploration 01  \n",
    "## Rock Paper Scissor\n",
    "---\n",
    "### 인공지능과 가위바위보 하기\n",
    "---\n",
    "### 목차\n",
    "---\n",
    "#### 01. 인공지능과 가위바위보 하기\n",
    "#### 02. 데이터를 준비하자!\n",
    "#### 03. 딥러닝 네트워크 설계하기\n",
    "#### 04. 딥러닝 네트워크 학습시키기\n",
    "#### 05. 얼마나 잘 만들었는지 확인하기\n",
    "#### 06. 더 좋은 네트워크 만들어 보기\n",
    "#### 07. 프로젝트 : 가위바위보 분류기 만들기\n",
    "#### 08. 프로젝트 제출\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 루브릭 (프로젝트 평가 기준)\n",
    "---\n",
    "#### 01. 이미지 분류기 모델이 성공적으로 만들어졌는가?\n",
    "트레이닝이 정상적으로 수행되었음\n",
    "\n",
    "#### 02. 오버피팅을 극복하기 위한 적절한 시도가 있었는가?\n",
    "데이터셋의 다양성, 정규화 등의 시도가 적절하였음\n",
    "\n",
    "#### 03. 분류모델의 Test Accuracy가 기준 이상 높게 나왔는가?\n",
    "60% 이상 도달하였음\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 프로젝트 결과물\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 준비\n",
    "---\n",
    "\n",
    "+ 데이터 불러오기 및 Resize 하기\n",
    "\n",
    "숫자 손글씨의 경우 이미지 크기가 28x28 이었기 때문에, 우리의 가위, 바위, 보 이미지도 28x28로 만들어야 함, 이를 위해서는 PIL 라이브러리를 사용, 혹시 PIL 라이브러리가 없는 경우 필요한 패키지를 설치\n",
    "\n",
    "```\n",
    "pip install pillow\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PIL 라이브러리 설치\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in ./anaconda3/envs/aiffel/lib/python3.7/site-packages (8.0.1)\n",
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "# PIL 라이브러리가 설치되어 있지 않다면 설치\n",
    "!pip install pillow   \n",
    "\n",
    "from PIL import Image\n",
    "import os, glob\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이미지 Resize\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/ssac30/aiffel/rock_scissor_paper/train/01/scissor\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/train/01/scissor\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.*\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/ssac30/aiffel/rock_scissor_paper/train/01/rock\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/train/01/rock\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/ssac30/aiffel/rock_scissor_paper/train/01/paper\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/train/01/paper\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.*\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "숫자 손글씨 인식기는 mnist.load_data() 라는 함수로 데이터를 읽었음, 가위, 바위, 보 데이터를 읽을 수 있는 load_data() 함수를 활용하면 임의의 사진 데이터(ex. 귤이 잘 익었나, 안 익었나? 웃는 얼굴인가, 우는 얼굴인가, 평범한 표정의 얼굴인가? 등)에 적용 가능\n",
    "\n",
    "load_data() 함수는 입력으로 이미지가 있는 폴더 위치를 받음. 여기서는 rock_scissor_paper 폴더 위치를 적어주면 됨. 그리고, 숫자 손글씨는 0~9 까지의 클래스가 있었던 것 기억하시죠? 가위바위보의 경우 3개의 클래스 즉, 가위: 0, 바위: 1, 보: 2 로 라벨링이 될 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_train shape: (300, 28, 28, 3)\n",
      "y_train shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=300   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/train/01\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 설계\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 하이퍼파라미터\n",
    "\n",
    "train images=300\n",
    "\n",
    "n_channel_1=16  \n",
    "n_channel_2=32  \n",
    "n_dense=32  \n",
    "n_train_epoch=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 30,819\n",
      "Trainable params: 30,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# model을 직접 만들어 보세요.\n",
    "# Hint! model의 입력/출력부에 특히 유의해 주세요. 가위바위보 데이터셋은 MNIST 데이터셋과 어떤 점이 달라졌나요?\n",
    "# [[YOUR CODE]]\n",
    "\n",
    "n_channel_1=16\n",
    "n_channel_2=32\n",
    "n_dense=32\n",
    "n_train_epoch=10\n",
    "\n",
    "model1=keras.models.Sequential()\n",
    "model1.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model1.add(keras.layers.MaxPool2D(2,2))\n",
    "model1.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model1.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model1.add(keras.layers.Flatten())\n",
    "model1.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model1.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ssac30/aiffel/rock_scissor_paper/train/01\n",
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_train_1 shape: (300, 28, 28, 3)\n",
      "y_train_1 shape: (300,)\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0725 - accuracy: 0.4500\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9503 - accuracy: 0.6600\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8007 - accuracy: 0.6633\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6471 - accuracy: 0.7633\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5115 - accuracy: 0.8333\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4094 - accuracy: 0.8533\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3702 - accuracy: 0.8633\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2966 - accuracy: 0.9067\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3060 - accuracy: 0.8733\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3300 - accuracy: 0.8667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fabac541c90>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.compile()과 model.fit()을 사용해 봅시다.\n",
    "# [[YOUR CODE]]\n",
    "\n",
    "def load_data(img_path):\n",
    "   # 가위 : 0, 바위 : 1, 보 : 2\n",
    "   number_of_data=300   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "   img_size=28\n",
    "   color=3\n",
    "   #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "   imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "   labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "   idx=0\n",
    "   for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "       img = np.array(Image.open(file),dtype=np.int32)\n",
    "       imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "       labels[idx]=0   # 가위 : 0\n",
    "       idx=idx+1\n",
    "\n",
    "   for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "       img = np.array(Image.open(file),dtype=np.int32)\n",
    "       imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "       labels[idx]=1   # 바위 : 1\n",
    "       idx=idx+1      \n",
    "  \n",
    "   for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "       img = np.array(Image.open(file),dtype=np.int32)\n",
    "       imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "       labels[idx]=2   # 보 : 2\n",
    "       idx=idx+1\n",
    "      \n",
    "   print(\"학습데이터(x_train)의 이미지 개수는\",idx,\"입니다.\")\n",
    "   return imgs, labels\n",
    "\n",
    "image_dir_path_1 = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/train/01\"\n",
    "print(image_dir_path_1)\n",
    "(x_train_1, y_train_1)=load_data(image_dir_path_1)\n",
    "\n",
    "print(\"x_train_1 shape: {}\".format(x_train_1.shape))\n",
    "print(\"y_train_1 shape: {}\".format(y_train_1.shape))\n",
    "\n",
    "x_train_norm_1 = x_train_1/255.0\n",
    "\n",
    "x_train_reshaped_1=x_train_norm_1.reshape( -1, 28, 28, 3)\n",
    "\n",
    "model1.compile(optimizer='adam',\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "# plt.imshow(x_train_1[0])\n",
    "# print('라벨: ', y_train_1[0])\n",
    "\n",
    "model1.fit(x_train_reshaped_1, y_train_1, epochs=n_train_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 테스트 (평가)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 하이퍼파라미터  \n",
    "test images=306"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/ssac30/aiffel/rock_scissor_paper/test/01/scissor\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/01/scissor\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/ssac30/aiffel/rock_scissor_paper/test/01/rock\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/01/rock\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/ssac30/aiffel/rock_scissor_paper/test/01/paper\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/01/paper\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.compile()과 model.fit()을 사용해 봅시다.\n",
    "# [[YOUR CODE]]\n",
    "\n",
    "def load_data(img_path):\n",
    "   # 가위 : 0, 바위 : 1, 보 : 2\n",
    "   number_of_data=106+100+100   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "   img_size=28\n",
    "   color=3\n",
    "   #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "   imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "   labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "   idx=0\n",
    "   for file in glob.iglob(img_path+'/scissor/*.*'):\n",
    "       img = np.array(Image.open(file),dtype=np.int32)\n",
    "       imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "       labels[idx]=0   # 가위 : 0\n",
    "       idx=idx+1\n",
    "\n",
    "   for file in glob.iglob(img_path+'/rock/*.*'):\n",
    "       img = np.array(Image.open(file),dtype=np.int32)\n",
    "       imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "       labels[idx]=1   # 바위 : 1\n",
    "       idx=idx+1      \n",
    "  \n",
    "   for file in glob.iglob(img_path+'/paper/*.*'):\n",
    "       img = np.array(Image.open(file),dtype=np.int32)\n",
    "       imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "       labels[idx]=2   # 보 : 2\n",
    "       idx=idx+1\n",
    "      \n",
    "   print(\"학습데이터(x_train)의 이미지 개수는\",idx,\"입니다.\")\n",
    "   return imgs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 306 입니다.\n"
     ]
    }
   ],
   "source": [
    "# x_test, y_test를 만드는 방법은 x_train, y_train을 만드는 방법과 아주 유사합니다.\n",
    "# [[YOUR CODE]]\n",
    "\n",
    "image_dir_path_2 = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/01\"\n",
    "(x_test_1, y_test_1)=load_data(image_dir_path_2)\n",
    "\n",
    "x_test_norm_1 = x_test_1 / 255.0\n",
    "\n",
    "x_test_reshaped_1=x_test_norm_1.reshape( -1, 28, 28, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 1.2160 - accuracy: 0.5523\n",
      "test_loss: 1.2159556150436401 \n",
      "test_accuracy: 0.5522875785827637\n"
     ]
    }
   ],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.evaluate()을 사용해 봅시다.\n",
    "# [[YOUR CODE]]\n",
    "\n",
    "test_loss, test_accuracy = model1.evaluate(x_test_reshaped_1,y_test_1, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습용 데이터 테스트 데이터 Loss & Accuracy\n",
    "---\n",
    "\n",
    "#### 학습용 데이터 : AVG 0.7733 / MIN 0.4500 / MAX 0.9067\n",
    "\n",
    "Epoch 01/10\n",
    "10/10 [==============================] - 0s 3ms/step - loss: 1.0725 - accuracy: 0.4500  \n",
    "Epoch 02/10\n",
    "10/10 [==============================] - 0s 3ms/step - loss: 0.9503 - accuracy: 0.6600  \n",
    "Epoch 03/10\n",
    "10/10 [==============================] - 0s 3ms/step - loss: 0.8007 - accuracy: 0.6633  \n",
    "Epoch 04/10\n",
    "10/10 [==============================] - 0s 4ms/step - loss: 0.6471 - accuracy: 0.7633  \n",
    "Epoch 05/10\n",
    "10/10 [==============================] - 0s 4ms/step - loss: 0.5115 - accuracy: 0.8333  \n",
    "Epoch 06/10\n",
    "10/10 [==============================] - 0s 4ms/step - loss: 0.4094 - accuracy: 0.8533  \n",
    "Epoch 07/10\n",
    "10/10 [==============================] - 0s 4ms/step - loss: 0.3702 - accuracy: 0.8633  \n",
    "Epoch 08/10\n",
    "10/10 [==============================] - 0s 4ms/step - loss: 0.2966 - accuracy: 0.9067  \n",
    "Epoch 09/10\n",
    "10/10 [==============================] - 0s 4ms/step - loss: 0.3060 - accuracy: 0.8733  \n",
    "Epoch 10/10\n",
    "10/10 [==============================] - 0s 4ms/step - loss: 0.3300 - accuracy: 0.8667  \n",
    "\n",
    "\n",
    "#### 테스트 데이터 : 0.5523\n",
    "\n",
    "10/10 - 0s - loss: 1.2160 - accuracy: 0.5523  \n",
    "test_loss: 1.2159556150436401  \n",
    "test_accuracy: 0.5522875785827637"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 개선 # 01\n",
    "---\n",
    "+ 하이퍼 파라미터 변경\n",
    "  + n_channel_1=32, 16 > 32 (2배)\n",
    "  + n_channel_2=64, 32 > 64 (2배)\n",
    "  + n_dense=64, 32 > 64 (2배)\n",
    "  + epoch 증가 : 10 > 20 (2배)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 설계\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 하이퍼파라미터\n",
    "\n",
    "train images=300\n",
    "\n",
    "n_channel_1=32 (16 > 32, 2배)  \n",
    "n_channel_2=64 (32 > 64, 2배)  \n",
    "n_dense=32 (16 > 32, 2배)  \n",
    "n_train_epoch=20 (10 > 20, 2배)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                102464    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 122,051\n",
      "Trainable params: 122,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# model을 직접 만들어 보세요.\n",
    "# Hint! model의 입력/출력부에 특히 유의해 주세요. 가위바위보 데이터셋은 MNIST 데이터셋과 어떤 점이 달라졌나요?\n",
    "# [[YOUR CODE]]\n",
    "\n",
    "n_channel_1=32\n",
    "n_channel_2=64\n",
    "n_dense=64\n",
    "n_train_epoch=20\n",
    "\n",
    "model1=keras.models.Sequential()\n",
    "model1.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model1.add(keras.layers.MaxPool2D(2,2))\n",
    "model1.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model1.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model1.add(keras.layers.Flatten())\n",
    "model1.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model1.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ssac30/aiffel/rock_scissor_paper/train/01\n",
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_train_1 shape: (300, 28, 28, 3)\n",
      "y_train_1 shape: (300,)\n",
      "Epoch 1/20\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0305 - accuracy: 0.4833\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8015 - accuracy: 0.7167\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5581 - accuracy: 0.7867\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4227 - accuracy: 0.8433\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3395 - accuracy: 0.8800\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2517 - accuracy: 0.9033\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2181 - accuracy: 0.9300\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1735 - accuracy: 0.9567\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1187 - accuracy: 0.9833\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1009 - accuracy: 0.9800\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0760 - accuracy: 0.9867\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0574 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0509 - accuracy: 0.9967\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0346 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0199 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0151 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0116 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0098 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0068 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fabbe741950>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.compile()과 model.fit()을 사용해 봅시다.\n",
    "# [[YOUR CODE]]\n",
    "\n",
    "def load_data(img_path):\n",
    "   # 가위 : 0, 바위 : 1, 보 : 2\n",
    "   number_of_data=300   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "   img_size=28\n",
    "   color=3\n",
    "   #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "   imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "   labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "   idx=0\n",
    "   for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "       img = np.array(Image.open(file),dtype=np.int32)\n",
    "       imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "       labels[idx]=0   # 가위 : 0\n",
    "       idx=idx+1\n",
    "\n",
    "   for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "       img = np.array(Image.open(file),dtype=np.int32)\n",
    "       imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "       labels[idx]=1   # 바위 : 1\n",
    "       idx=idx+1      \n",
    "  \n",
    "   for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "       img = np.array(Image.open(file),dtype=np.int32)\n",
    "       imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "       labels[idx]=2   # 보 : 2\n",
    "       idx=idx+1\n",
    "      \n",
    "   print(\"학습데이터(x_train)의 이미지 개수는\",idx,\"입니다.\")\n",
    "   return imgs, labels\n",
    "\n",
    "image_dir_path_1 = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/train/01\"\n",
    "print(image_dir_path_1)\n",
    "(x_train_1, y_train_1)=load_data(image_dir_path_1)\n",
    "\n",
    "print(\"x_train_1 shape: {}\".format(x_train_1.shape))\n",
    "print(\"y_train_1 shape: {}\".format(y_train_1.shape))\n",
    "\n",
    "x_train_norm_1 = x_train_1/255.0\n",
    "\n",
    "x_train_reshaped_1=x_train_norm_1.reshape( -1, 28, 28, 3)\n",
    "\n",
    "model1.compile(optimizer='adam',\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "# plt.imshow(x_train_1[0])\n",
    "# print('라벨: ', y_train_1[0])\n",
    "\n",
    "model1.fit(x_train_reshaped_1, y_train_1, epochs=n_train_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 테스트 (평가)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 하이퍼파라미터  \n",
    "test images=306"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/ssac30/aiffel/rock_scissor_paper/test/01/scissor\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/01/scissor\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/ssac30/aiffel/rock_scissor_paper/test/01/rock\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/01/rock\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/ssac30/aiffel/rock_scissor_paper/test/01/paper\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/01/paper\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.compile()과 model.fit()을 사용해 봅시다.\n",
    "# [[YOUR CODE]]\n",
    "\n",
    "def load_data(img_path):\n",
    "   # 가위 : 0, 바위 : 1, 보 : 2\n",
    "   number_of_data=106+100+100   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "   img_size=28\n",
    "   color=3\n",
    "   #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "   imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "   labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "   idx=0\n",
    "   for file in glob.iglob(img_path+'/scissor/*.*'):\n",
    "       img = np.array(Image.open(file),dtype=np.int32)\n",
    "       imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "       labels[idx]=0   # 가위 : 0\n",
    "       idx=idx+1\n",
    "\n",
    "   for file in glob.iglob(img_path+'/rock/*.*'):\n",
    "       img = np.array(Image.open(file),dtype=np.int32)\n",
    "       imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "       labels[idx]=1   # 바위 : 1\n",
    "       idx=idx+1      \n",
    "  \n",
    "   for file in glob.iglob(img_path+'/paper/*.*'):\n",
    "       img = np.array(Image.open(file),dtype=np.int32)\n",
    "       imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "       labels[idx]=2   # 보 : 2\n",
    "       idx=idx+1\n",
    "      \n",
    "   print(\"학습데이터(x_train)의 이미지 개수는\",idx,\"입니다.\")\n",
    "   return imgs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 306 입니다.\n"
     ]
    }
   ],
   "source": [
    "# x_test, y_test를 만드는 방법은 x_train, y_train을 만드는 방법과 아주 유사합니다.\n",
    "# [[YOUR CODE]]\n",
    "\n",
    "image_dir_path_2 = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/01\"\n",
    "(x_test_1, y_test_1)=load_data(image_dir_path_2)\n",
    "\n",
    "x_test_norm_1 = x_test_1 / 255.0\n",
    "\n",
    "x_test_reshaped_1=x_test_norm_1.reshape( -1, 28, 28, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 1.9613 - accuracy: 0.5163\n",
      "test_loss: 1.9612510204315186 \n",
      "test_accuracy: 0.516339898109436\n"
     ]
    }
   ],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.evaluate()을 사용해 봅시다.\n",
    "# [[YOUR CODE]]\n",
    "\n",
    "test_loss, test_accuracy = model1.evaluate(x_test_reshaped_1,y_test_1, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습용 데이터 테스트 데이터 Loss & Accuracy\n",
    "---\n",
    "\n",
    "#### 학습용 데이터 : AVG 0.922335 / MIN 0.4833 / MAX 1\n",
    "\n",
    "Epoch 01/20\n",
    "10/10 [==============================] - 0s 5ms/step - loss: 1.0305 - accuracy: 0.4833  \n",
    "Epoch 02/20\n",
    "10/10 [==============================] - 0s 5ms/step - loss: 0.8015 - accuracy: 0.7167  \n",
    "Epoch 03/20\n",
    "10/10 [==============================] - 0s 5ms/step - loss: 0.5581 - accuracy: 0.7867  \n",
    "Epoch 04/20\n",
    "10/10 [==============================] - 0s 5ms/step - loss: 0.4227 - accuracy: 0.8433  \n",
    "Epoch 05/20\n",
    "10/10 [==============================] - 0s 5ms/step - loss: 0.3395 - accuracy: 0.8800  \n",
    "Epoch 06/20\n",
    "10/10 [==============================] - 0s 5ms/step - loss: 0.2517 - accuracy: 0.9033  \n",
    "Epoch 07/20\n",
    "10/10 [==============================] - 0s 5ms/step - loss: 0.2181 - accuracy: 0.9300  \n",
    "Epoch 08/20\n",
    "10/10 [==============================] - 0s 5ms/step - loss: 0.1735 - accuracy: 0.9567  \n",
    "Epoch 09/20\n",
    "10/10 [==============================] - 0s 5ms/step - loss: 0.1187 - accuracy: 0.9833  \n",
    "Epoch 10/20\n",
    "10/10 [==============================] - 0s 5ms/step - loss: 0.1009 - accuracy: 0.9800  \n",
    "Epoch 11/20\n",
    "10/10 [==============================] - 0s 5ms/step - loss: 0.0760 - accuracy: 0.9867  \n",
    "Epoch 12/20\n",
    "10/10 [==============================] - 0s 5ms/step - loss: 0.0574 - accuracy: 1.0000  \n",
    "Epoch 13/20\n",
    "10/10 [==============================] - 0s 5ms/step - loss: 0.0509 - accuracy: 0.9967  \n",
    "Epoch 14/20\n",
    "10/10 [==============================] - 0s 6ms/step - loss: 0.0346 - accuracy: 1.0000  \n",
    "Epoch 15/20\n",
    "10/10 [==============================] - 0s 5ms/step - loss: 0.0199 - accuracy: 1.0000  \n",
    "Epoch 16/20\n",
    "10/10 [==============================] - 0s 5ms/step - loss: 0.0151 - accuracy: 1.0000  \n",
    "Epoch 17/20\n",
    "10/10 [==============================] - 0s 5ms/step - loss: 0.0116 - accuracy: 1.0000  \n",
    "Epoch 18/20\n",
    "10/10 [==============================] - 0s 5ms/step - loss: 0.0098 - accuracy: 1.0000  \n",
    "Epoch 19/20\n",
    "10/10 [==============================] - 0s 5ms/step - loss: 0.0081 - accuracy: 1.0000  \n",
    "Epoch 20/20\n",
    "10/10 [==============================] - 0s 5ms/step - loss: 0.0068 - accuracy: 1.0000  \n",
    "\n",
    "\n",
    "#### 테스트 데이터 : 0.5163\n",
    "\n",
    "10/10 - 0s - loss: 1.9613 - accuracy: 0.5163  \n",
    "test_loss: 1.9612510204315186  \n",
    "test_accuracy: 0.516339898109436"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 개선 # 02\n",
    "---\n",
    "+ 학습용 데이터 증대 : 300 > 3000 (10배)\n",
    "+ 하이퍼 파라미터 변경\n",
    "  + n_channel_1=32, 16 > 32 (2배)\n",
    "  + n_channel_2=64, 32 > 64 (2배)\n",
    "  + n_dense=64, 32 > 64 (2배)\n",
    "  + epoch 증가 : 10 > 20 (2배)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이미지 Resize\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/ssac30/aiffel/rock_scissor_paper/train/02/scissor\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/train/02/scissor\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.*\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/ssac30/aiffel/rock_scissor_paper/train/02/rock\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/train/02/rock\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/ssac30/aiffel/rock_scissor_paper/train/02/paper\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/train/02/paper\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.*\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "숫자 손글씨 인식기는 mnist.load_data() 라는 함수로 데이터를 읽었음, 가위, 바위, 보 데이터를 읽을 수 있는 load_data() 함수를 활용하면 임의의 사진 데이터(ex. 귤이 잘 익었나, 안 익었나? 웃는 얼굴인가, 우는 얼굴인가, 평범한 표정의 얼굴인가? 등)에 적용 가능\n",
    "\n",
    "load_data() 함수는 입력으로 이미지가 있는 폴더 위치를 받음. 여기서는 rock_scissor_paper 폴더 위치를 적어주면 됨. 그리고, 숫자 손글씨는 0~9 까지의 클래스가 있었던 것 기억하시죠? 가위바위보의 경우 3개의 클래스 즉, 가위: 0, 바위: 1, 보: 2 로 라벨링이 될 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 3300 입니다.\n",
      "x_train shape: (3300, 28, 28, 3)\n",
      "y_train shape: (3300,)\n"
     ]
    }
   ],
   "source": [
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=3300   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/train/02\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 설계\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 하이퍼파라미터\n",
    "\n",
    "train images=3300\n",
    "\n",
    "n_channel_1=32  \n",
    "n_channel_2=64  \n",
    "n_dense=64  \n",
    "n_train_epoch=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                102464    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 122,051\n",
      "Trainable params: 122,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# model을 직접 만들어 보세요.\n",
    "# Hint! model의 입력/출력부에 특히 유의해 주세요. 가위바위보 데이터셋은 MNIST 데이터셋과 어떤 점이 달라졌나요?\n",
    "# [[YOUR CODE]]\n",
    "\n",
    "n_channel_1=32\n",
    "n_channel_2=64\n",
    "n_dense=64\n",
    "n_train_epoch=20\n",
    "\n",
    "model1=keras.models.Sequential()\n",
    "model1.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model1.add(keras.layers.MaxPool2D(2,2))\n",
    "model1.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model1.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model1.add(keras.layers.Flatten())\n",
    "model1.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model1.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ssac30/aiffel/rock_scissor_paper/train/02\n",
      "학습데이터(x_train)의 이미지 개수는 3300 입니다.\n",
      "x_train_1 shape: (3300, 28, 28, 3)\n",
      "y_train_1 shape: (3300,)\n",
      "Epoch 1/20\n",
      "104/104 [==============================] - 1s 5ms/step - loss: 1.0727 - accuracy: 0.3991\n",
      "Epoch 2/20\n",
      "104/104 [==============================] - 1s 5ms/step - loss: 0.8099 - accuracy: 0.6530\n",
      "Epoch 3/20\n",
      "104/104 [==============================] - 1s 5ms/step - loss: 0.5278 - accuracy: 0.7909\n",
      "Epoch 4/20\n",
      "104/104 [==============================] - 1s 5ms/step - loss: 0.3654 - accuracy: 0.8670\n",
      "Epoch 5/20\n",
      "104/104 [==============================] - 1s 6ms/step - loss: 0.2681 - accuracy: 0.9100\n",
      "Epoch 6/20\n",
      "104/104 [==============================] - 1s 6ms/step - loss: 0.2023 - accuracy: 0.9315\n",
      "Epoch 7/20\n",
      "104/104 [==============================] - 1s 5ms/step - loss: 0.1553 - accuracy: 0.9503\n",
      "Epoch 8/20\n",
      "104/104 [==============================] - 1s 5ms/step - loss: 0.1149 - accuracy: 0.9645\n",
      "Epoch 9/20\n",
      "104/104 [==============================] - 1s 6ms/step - loss: 0.0985 - accuracy: 0.9721\n",
      "Epoch 10/20\n",
      "104/104 [==============================] - 1s 6ms/step - loss: 0.0754 - accuracy: 0.9815\n",
      "Epoch 11/20\n",
      "104/104 [==============================] - 1s 5ms/step - loss: 0.0653 - accuracy: 0.9818\n",
      "Epoch 12/20\n",
      "104/104 [==============================] - 1s 5ms/step - loss: 0.0461 - accuracy: 0.9882\n",
      "Epoch 13/20\n",
      "104/104 [==============================] - 1s 5ms/step - loss: 0.0351 - accuracy: 0.9918\n",
      "Epoch 14/20\n",
      "104/104 [==============================] - 1s 5ms/step - loss: 0.0309 - accuracy: 0.9927\n",
      "Epoch 15/20\n",
      "104/104 [==============================] - 1s 5ms/step - loss: 0.0281 - accuracy: 0.9927\n",
      "Epoch 16/20\n",
      "104/104 [==============================] - 1s 5ms/step - loss: 0.0285 - accuracy: 0.9933\n",
      "Epoch 17/20\n",
      "104/104 [==============================] - 1s 5ms/step - loss: 0.0120 - accuracy: 0.9994\n",
      "Epoch 18/20\n",
      "104/104 [==============================] - 1s 5ms/step - loss: 0.0115 - accuracy: 0.9985\n",
      "Epoch 19/20\n",
      "104/104 [==============================] - 1s 5ms/step - loss: 0.0080 - accuracy: 0.9991\n",
      "Epoch 20/20\n",
      "104/104 [==============================] - 1s 5ms/step - loss: 0.0060 - accuracy: 0.9994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fabac1712d0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.compile()과 model.fit()을 사용해 봅시다.\n",
    "# [[YOUR CODE]]\n",
    "\n",
    "def load_data(img_path):\n",
    "   # 가위 : 0, 바위 : 1, 보 : 2\n",
    "   number_of_data=3300   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "   img_size=28\n",
    "   color=3\n",
    "   #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "   imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "   labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "   idx=0\n",
    "   for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "       img = np.array(Image.open(file),dtype=np.int32)\n",
    "       imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "       labels[idx]=0   # 가위 : 0\n",
    "       idx=idx+1\n",
    "\n",
    "   for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "       img = np.array(Image.open(file),dtype=np.int32)\n",
    "       imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "       labels[idx]=1   # 바위 : 1\n",
    "       idx=idx+1      \n",
    "  \n",
    "   for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "       img = np.array(Image.open(file),dtype=np.int32)\n",
    "       imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "       labels[idx]=2   # 보 : 2\n",
    "       idx=idx+1\n",
    "      \n",
    "   print(\"학습데이터(x_train)의 이미지 개수는\",idx,\"입니다.\")\n",
    "   return imgs, labels\n",
    "\n",
    "image_dir_path_1 = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/train/02\"\n",
    "print(image_dir_path_1)\n",
    "(x_train_1, y_train_1)=load_data(image_dir_path_1)\n",
    "\n",
    "print(\"x_train_1 shape: {}\".format(x_train_1.shape))\n",
    "print(\"y_train_1 shape: {}\".format(y_train_1.shape))\n",
    "\n",
    "x_train_norm_1 = x_train_1/255.0\n",
    "\n",
    "x_train_reshaped_1=x_train_norm_1.reshape( -1, 28, 28, 3)\n",
    "\n",
    "model1.compile(optimizer='adam',\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "# plt.imshow(x_train_1[0])\n",
    "# print('라벨: ', y_train_1[0])\n",
    "\n",
    "model1.fit(x_train_reshaped_1, y_train_1, epochs=n_train_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 테스트 (평가)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 하이퍼파라미터  \n",
    "test images=306"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/ssac30/aiffel/rock_scissor_paper/test/02/scissor\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/02/scissor\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/ssac30/aiffel/rock_scissor_paper/test/02/rock\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/02/rock\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/ssac30/aiffel/rock_scissor_paper/test/02/paper\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/02/paper\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.compile()과 model.fit()을 사용해 봅시다.\n",
    "# [[YOUR CODE]]\n",
    "\n",
    "def load_data(img_path):\n",
    "   # 가위 : 0, 바위 : 1, 보 : 2\n",
    "   number_of_data=106+100+100   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "   img_size=28\n",
    "   color=3\n",
    "   #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "   imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "   labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "   idx=0\n",
    "   for file in glob.iglob(img_path+'/scissor/*.*'):\n",
    "       img = np.array(Image.open(file),dtype=np.int32)\n",
    "       imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "       labels[idx]=0   # 가위 : 0\n",
    "       idx=idx+1\n",
    "\n",
    "   for file in glob.iglob(img_path+'/rock/*.*'):\n",
    "       img = np.array(Image.open(file),dtype=np.int32)\n",
    "       imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "       labels[idx]=1   # 바위 : 1\n",
    "       idx=idx+1      \n",
    "  \n",
    "   for file in glob.iglob(img_path+'/paper/*.*'):\n",
    "       img = np.array(Image.open(file),dtype=np.int32)\n",
    "       imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "       labels[idx]=2   # 보 : 2\n",
    "       idx=idx+1\n",
    "      \n",
    "   print(\"학습데이터(x_train)의 이미지 개수는\",idx,\"입니다.\")\n",
    "   return imgs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 306 입니다.\n"
     ]
    }
   ],
   "source": [
    "# x_test, y_test를 만드는 방법은 x_train, y_train을 만드는 방법과 아주 유사합니다.\n",
    "# [[YOUR CODE]]\n",
    "\n",
    "image_dir_path_2 = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/02\"\n",
    "(x_test_1, y_test_1)=load_data(image_dir_path_2)\n",
    "\n",
    "x_test_norm_1 = x_test_1 / 255.0\n",
    "\n",
    "x_test_reshaped_1=x_test_norm_1.reshape( -1, 28, 28, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 2.3323 - accuracy: 0.6111\n",
      "test_loss: 2.3322503566741943 \n",
      "test_accuracy: 0.6111111044883728\n"
     ]
    }
   ],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.evaluate()을 사용해 봅시다.\n",
    "# [[YOUR CODE]]\n",
    "\n",
    "test_loss, test_accuracy = model1.evaluate(x_test_reshaped_1,y_test_1, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습용 데이터 테스트 데이터 Loss & Accuracy\n",
    "---\n",
    "\n",
    "#### 학습용 데이터 : AVG 0.9178 / MIN 0.3991 / MAX 0.9994\n",
    "\n",
    "Epoch 01/20\n",
    "104/104 [==============================] - 1s 5ms/step - loss: 1.0727 - accuracy: 0.3991  \n",
    "Epoch 02/20\n",
    "104/104 [==============================] - 1s 5ms/step - loss: 0.8099 - accuracy: 0.6530  \n",
    "Epoch 03/20\n",
    "104/104 [==============================] - 1s 5ms/step - loss: 0.5278 - accuracy: 0.7909  \n",
    "Epoch 04/20\n",
    "104/104 [==============================] - 1s 5ms/step - loss: 0.3654 - accuracy: 0.8670  \n",
    "Epoch 05/20\n",
    "104/104 [==============================] - 1s 6ms/step - loss: 0.2681 - accuracy: 0.9100  \n",
    "Epoch 06/20\n",
    "104/104 [==============================] - 1s 6ms/step - loss: 0.2023 - accuracy: 0.9315  \n",
    "Epoch 07/20\n",
    "104/104 [==============================] - 1s 5ms/step - loss: 0.1553 - accuracy: 0.9503  \n",
    "Epoch 08/20\n",
    "104/104 [==============================] - 1s 5ms/step - loss: 0.1149 - accuracy: 0.9645  \n",
    "Epoch 09/20\n",
    "104/104 [==============================] - 1s 6ms/step - loss: 0.0985 - accuracy: 0.9721  \n",
    "Epoch 10/20\n",
    "104/104 [==============================] - 1s 6ms/step - loss: 0.0754 - accuracy: 0.9815  \n",
    "Epoch 11/20\n",
    "104/104 [==============================] - 1s 5ms/step - loss: 0.0653 - accuracy: 0.9818  \n",
    "Epoch 12/20\n",
    "104/104 [==============================] - 1s 5ms/step - loss: 0.0461 - accuracy: 0.9882  \n",
    "Epoch 13/20\n",
    "104/104 [==============================] - 1s 5ms/step - loss: 0.0351 - accuracy: 0.9918  \n",
    "Epoch 14/20\n",
    "104/104 [==============================] - 1s 5ms/step - loss: 0.0309 - accuracy: 0.9927  \n",
    "Epoch 15/20\n",
    "104/104 [==============================] - 1s 5ms/step - loss: 0.0281 - accuracy: 0.9927  \n",
    "Epoch 16/20\n",
    "104/104 [==============================] - 1s 5ms/step - loss: 0.0285 - accuracy: 0.9933  \n",
    "Epoch 17/20\n",
    "104/104 [==============================] - 1s 5ms/step - loss: 0.0120 - accuracy: 0.9994  \n",
    "Epoch 18/20\n",
    "104/104 [==============================] - 1s 5ms/step - loss: 0.0115 - accuracy: 0.9985  \n",
    "Epoch 19/20\n",
    "104/104 [==============================] - 1s 5ms/step - loss: 0.0080 - accuracy: 0.9991  \n",
    "Epoch 20/20\n",
    "104/104 [==============================] - 1s 5ms/step - loss: 0.0060 - accuracy: 0.9994  \n",
    "\n",
    "\n",
    "\n",
    "#### 테스트 데이터 : 0.6111\n",
    "\n",
    "10/10 - 0s - loss: 2.3323 - accuracy: 0.6111  \n",
    "test_loss: 2.3322503566741943  \n",
    "test_accuracy: 0.6111111044883728"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결과 정리\n",
    "---\n",
    "\n",
    "### 초기 모델\n",
    "---\n",
    "\n",
    "하이퍼파라미터\n",
    "train images=300\n",
    "\n",
    "n_channel_1=16\n",
    "n_channel_2=32\n",
    "n_dense=32\n",
    "n_train_epoch=10\n",
    "\n",
    "\n",
    "#### 학습용 데이터 : AVG 0.7733 / MIN 0.4500 / MAX 0.9067\n",
    "#### 테스트 데이터 : 0.5523\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### 모델 개선 # 01 : 하이퍼파라미터를 증가시켰음에도 테스트 데이터의 정확도는 오히려 떨어짐\n",
    "### (전 : 0.5523 / 후 : 0.5163)\n",
    "---\n",
    "하이퍼파라미터\n",
    "train images=300\n",
    "\n",
    "n_channel_1=32 (16 > 32, 2배)  \n",
    "n_channel_2=64 (32 > 64, 2배)  \n",
    "n_dense=32 (16 > 32, 2배)  \n",
    "n_train_epoch=20 (10 > 20, 2배)\n",
    "\n",
    "\n",
    "\n",
    "#### 학습용 데이터 : AVG 0.922335 / MIN 0.4833 / MAX 1\n",
    "#### 테스트 데이터 : 0.5163\n",
    "\n",
    "---\n",
    "\n",
    "### 모델 개선 # 02 : 학습용 데이터수를 10배 증가시키자 테스트 데이터의 정확도가 증가함\n",
    "### (전 : 0.5523 또는 0.5163 / 후 : 0.6111)\n",
    "---\n",
    "+ 학습용 데이터 증대 : 300 > 3000 (10배)\n",
    "+ 하이퍼 파라미터 변경\n",
    "  + n_channel_1=32, 16 > 32 (2배)\n",
    "  + n_channel_2=64, 32 > 64 (2배)\n",
    "  + n_dense=64, 32 > 64 (2배)\n",
    "  + epoch 증가 : 10 > 20 (2배)\n",
    "\n",
    "하이퍼파라미터\n",
    "train images=3300\n",
    "\n",
    "n_channel_1=32  \n",
    "n_channel_2=64  \n",
    "n_dense=64  \n",
    "n_train_epoch=20  \n",
    "\n",
    "#### 학습용 데이터 : AVG 0.9178 / MIN 0.3991 / MAX 0.9994\n",
    "#### 테스트 데이터 : 0.6111"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시험용 데이터(x_test)에 대한 인식률(test accuracy)이 train accuracy보다 많이 낮게 나오지는 않았나요?\n",
    "\n",
    "만약 그렇다면 그 이유는 무엇일까요? MNIST 손글씨 데이터 때처럼 test accuracy가 train accuracy에 근접하도록 개선 방법을 찾아 봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 테스트 데이터를 증가시키고\n",
    "2. 하이퍼파라미터를 조정 (증가하는 방향으로)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 로그\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 딥러닝 머신러닝 절차 : 데이터 준비 > 딥러닝 네트워크 설계 > 학습 > 테스트 (평가)\n",
    "01. 데이터 준비 : 데이터 준비 및 데이터 살펴보기\n",
    "02. 설계 : 머신러닝 모델 학습시키기 위한 문제지, 정답지 준비하기\n",
    "03. 학습 : 머신러닝 모델 학습시키기\n",
    "04. 테스트 (평가) : 머신러닝 모델 평가하기\n",
    "---\n",
    "\n",
    "+ Q. 딥러닝 네트워크 설계 : 왜 네트워크 설계라고 하는 건지?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 모델 : Sequential API를 이용할 예정\n",
    "+ tf.keras : TensorFlow의 표준 API\n",
    "+ matplotlib : 파이썬에서 제공하는 시각화(Visualization) 패키지인 Matplotlib은 차트(chart), 플롯(plot) 등 다양한 형태로 데이터를 시각화할 수 있는 강력한 기능을 제공\n",
    "+ TensorFlow : 구글(Google)에서 오픈소스로 제공하고 있으며, 가장 널리 사용되고 있는 머신러닝 라이브러리 중 하나\n",
    "+ 대부분의 딥러닝 구현실습은 TensorFlow Version 2.0 또는 그 이상 버전에서 진행\n",
    "\n",
    "---\n",
    "Keywords : TensorFlow, Sequentail API, MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01. 데이터 준비\n",
    "---\n",
    "MNIST 숫자 손글씨 Dataset 불러 들이기\n",
    "\n",
    "\n",
    "```\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "#\n",
    "mnist = keras.datasets.mnist\n",
    "\n",
    "# MNIST 데이터를 로드. 다운로드하지 않았다면 다운로드까지 자동으로 진행됩니다.\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "60000\n",
      "60000 10000 10000\n",
      "[[[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)   # Tensorflow의 버전을 출력\n",
    "\n",
    "mnist = keras.datasets.mnist\n",
    "\n",
    "# MNIST 데이터를 로드. 다운로드하지 않았다면 다운로드까지 자동으로 진행됩니다. \n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()   \n",
    "\n",
    "print(len(x_train))  # x_train 배열의 크기를 출력\n",
    "print(len(y_train), len(x_test), len(y_test))\n",
    "\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 준비된 데이터에서 숫자 손글씨 이미지 출력\n",
    "\n",
    "training data : 숫자 손글씨 이미지 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[1],cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training 결과값 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(y_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "traing data 및 결과값 동시에 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 번째 이미지의 숫자는 바로  4 입니다.\n"
     ]
    }
   ],
   "source": [
    "# index에 0에서 59999 사이 숫자를 지정해 보세요.\n",
    "index=2     \n",
    "plt.imshow(x_train[index],cmap=plt.cm.binary)\n",
    "plt.show()\n",
    "print( (index+1), '번째 이미지의 숫자는 바로 ',  y_train[index], '입니다.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습용 데이터와 시험용 데이터\n",
    "\n",
    "\n",
    "mnist.load( ) 함수를 통해 학습용 데이터 (x_train, y_train)와 시험용 데이터 (x_test, y_test)를 나누어서 받아들이는 것\n",
    "```\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "```\n",
    "\n",
    "+ 우리가 만든 숫자 손글씨 분류기는 학습용 데이터 (x_train, y_train)만을 가지고 학습\n",
    "+ 학습이 끝난 후에는 이 손글씨 분류기가 얼마나 좋은 성능을 보이는지 확인해보고 싶을 텐데요, 이 때 시험용 데이터(x_test,y_test)로 테스트\n",
    "\n",
    "\n",
    "+ MNIST 데이터셋은 약 500명 사용자가 작성한 숫자 이미지를 가지고 있음\n",
    "+ 그 중 250여명의 데이터가 학습용 데이터로, 다른 250여명의 데이터가 시험용 데이터로 이용\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습용 데이터\n",
    "\n",
    "(60000, 28, 28) : 28x28 크기의 숫자 이미지가 60,000장이 있다는 뜻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 시험용 데이터 / 검증용 데이터 (Validation Set)\n",
    "\n",
    "머신러닝 학습 과정이 정상적으로 진행되고 있는지, 오버피팅이 발생하고 있지 않은지, 학습을 중단해도 되는지 등을 확인하고 싶을 때\n",
    "\n",
    "(10000, 28, 28) : 28x28 크기의 숫자 이미지가 10,000장이 있다는 뜻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 교차 검증 (Cross Validation) 기법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 전처리하기 : 정규화\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 인공지능 모델을 훈련시키고 사용할 때, 일반적으로 입력은 0~1 사이의 값으로 정규화 시켜주는 것이 좋음\n",
    "+ MNIST 데이터는 각 픽셀의 값이 0~255 사이 범위에 있으므로 데이터들을 255.0 으로 나누어주면 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최소값: 0  최대값: 255\n"
     ]
    }
   ],
   "source": [
    "# 숫자 손글씨 이미지의 실제 픽셀 값은 0~255 사이의 값을 가짐\n",
    "print('최소값:',np.min(x_train), ' 최대값:',np.max(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최소값: 0.0  최대값: 1.0\n"
     ]
    }
   ],
   "source": [
    "x_train_norm, x_test_norm = x_train / 255.0, x_test / 255.0\n",
    "print('최소값:',np.min(x_train_norm), ' 최대값:',np.max(x_train_norm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Q : 인공지능 모델을 훈련시키고 사용할 때, 왜 0~1 사이의 값으로 정규화 시켜주는 것이 좋은지?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02. 모델 설계 : 딥러닝 네트워크 설계\n",
    "\n",
    "tf.keras의 Sequential API 사용 예정\n",
    "\n",
    "Sequential API는 개발의 자유도는 많이 떨어지지만, 매우 간단하게 딥러닝 모델을 만들어낼 수 있는 방법, 이 방법을 통해 미리 정의된 딥러닝 레이어(layer)를 손쉽게 추가 가능\n",
    "\n",
    "케라스에서 모델을 만드는 방법은 Sequential API 외에도 Functional API를 이용하는 방법, 밑바닥부터 직접 코딩하는 방법 등 여러 방법이 있음\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.keras의 Sequential API를 이용하여 LeNet이라는 딥러닝 네트워크를 설계한 예"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n"
     ]
    }
   ],
   "source": [
    "# keras의 Sequential API 모델을 사용\n",
    "model=keras.models.Sequential()\n",
    "\n",
    "# Conv2D(16, ...) 부분\n",
    "# 얼마나 다양한 이미지의 특징을 살펴볼 것인가? (입력 이미지가 다양할수록 더 많은 특징을 고려해보자?)\n",
    "# 입력 이미지를 다양하게 할수록 더 많은 특징을 고려해야 한다는 의미인지?\n",
    "# 이미지의 특징의 수, 여기서는 각각 16개와 32개\n",
    "# 우리의 숫자 이미지는 사실 매우 단순한 형태의 이미지\n",
    "# 만약 강아지 얼굴 사진이 입력 이미지라면 훨씬 디테일하고 복잡한 영상\n",
    "# 그럴 경우에는 이 특징 숫자를 늘려주는 것을 고려해 볼 수 있음\n",
    "\n",
    "# input_shape=(28,28,1)\n",
    "# 입력 이미지의 형태\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,1)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "\n",
    "# 분류기 알고리즘을 얼마나 복잡하게 할 것인가?\n",
    "# 복잡한 문제일수록 이 수를 늘려주는 것을 고려해 볼 수 있음\n",
    "# Dense 레이어의 첫 번째 인자는 분류기에 사용되는 뉴런의 숫자\n",
    "# 이 값이 클수록 보다 복잡한 분류기를 만들 수 있음\n",
    "# 10개의 숫자가 아닌 알파벳을 구분하고 싶다면, 대문자 26개, 소문자 26개로 총 52개의 클래스를 분류해 내야 함\n",
    "# 그래서 32보다 큰 64, 128 등을 고려해 볼 수 있을 것임\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "\n",
    "# 최종 분류기의 Class 수, 여기서는 0~9까지의 총 10개의 Class를 구분하므로 10\n",
    "# 마지막 Dense 레이어의 뉴런 숫자는 결과적으로 분류해 내야 하는 클래스 수로 지정\n",
    "# 숫자 인식기에서는 10, 알파벳 인식기에서는 52\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Q. MaxPool2D와 MaxPooling2D의 차이점은?\n",
    "+ Q. activation = 'relu', 'softmax' 이건 뭔지? 그리고 다른 activation들은 어떤 것들이 있는지?\n",
    "+ Q. 알파벳 분류기의 경우, 왜 분류기에 사용되는 뉴런의 숫자로 52가 아닌 32, 64, 128 등을 고려하는 건지?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리가 만든 딥러닝 네트워크 모델을 확인 : model.summary() 메소드를 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 30,762\n",
      "Trainable params: 30,762\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03. 모델 학습 : 딥러닝 네트워크 학습시키기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,1)))\n",
    "```\n",
    "\n",
    "+ 우리가 만든 네트워크의 입력은 (데이터갯수, 이미지 크기 x, 이미지 크기 y, 채널수) 와 같은 형태를 가짐 : input_shape=(28,28,1)\n",
    "+ 그런데 print(x_train.shape) 을 해보면,(60000, 28, 28) 로 채널수에 대한 정보가 없음. 따라서 (60000, 28, 28, 1) 로 만들어 주어야 함\n",
    "+ 여기서 채널수 1은 흑백 이미지를 의미, 컬러 이미지라면 R, G, B 세 가지 값이 있기 때문에 3이 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Reshape - x_train_norm shape: (60000, 28, 28)\n",
      "Before Reshape - x_test_norm shape: (10000, 28, 28)\n",
      "After Reshape - x_train_reshaped shape: (60000, 28, 28, 1)\n",
      "After Reshape - x_test_reshaped shape: (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Before Reshape - x_train_norm shape: {}\".format(x_train_norm.shape))\n",
    "print(\"Before Reshape - x_test_norm shape: {}\".format(x_test_norm.shape))\n",
    "\n",
    "x_train_reshaped=x_train_norm.reshape( -1, 28, 28, 1)  # 데이터갯수에 -1을 쓰면 reshape시 자동계산됩니다.\n",
    "x_test_reshaped=x_test_norm.reshape( -1, 28, 28, 1)\n",
    "\n",
    "print(\"After Reshape - x_train_reshaped shape: {}\".format(x_train_reshaped.shape))\n",
    "print(\"After Reshape - x_test_reshaped shape: {}\".format(x_test_reshaped.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x_train 학습 데이터로 딥러닝 네트워크를 학습, 여기서 epochs=10 은 전체 60,000개의 데이터를 10번 반복 사용해서 학습을 시키라는 뜻, 물론 model의 입력 정의에 형태를 맞춘 x_train_reshaped가 사용\n",
    "\n",
    "각 학습이 진행됨에 따라 epoch 별로 어느 정도 인식 정확도(accuracy)가 올라가는지 확인 가능, 인식 정확도가 0.9413에서 0.9957까지 매우 높게 올라감, 9 epoch정도부터는 인식률의 상승이 미미, 10 epoch정도 학습을 시키면 충분할 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1883 - accuracy: 0.9421\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0645 - accuracy: 0.9796\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0474 - accuracy: 0.9854\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0362 - accuracy: 0.9886\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0297 - accuracy: 0.9907\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0249 - accuracy: 0.9915\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0207 - accuracy: 0.9932\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0175 - accuracy: 0.9945\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0149 - accuracy: 0.9952\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0120 - accuracy: 0.9963\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fabb8489190>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_reshaped, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Q. 같은 데이터셋을 가지고 동일하게 실행했는데도 Epoch별로 Accuracy가 달라지는 이유는 뭔지?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트 (평가)\n",
    "\n",
    "#### 테스트 데이터로 성능 확인하기\n",
    "---\n",
    "\n",
    "인식 정확도는 학습용 데이터(x_train)을 가지고 구한 것, 연습문제를 잘푸는 인공지능을 만든 셈, 우리가 만든 딥러닝 네트워크는 실제 시험도 잘 볼 수 있을지 시험용 데이터(x_test)를 가지고 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.0330 - accuracy: 0.9893\n",
      "test_loss: 0.03300492465496063 \n",
      "test_accuracy: 0.989300012588501\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test_reshaped,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습용 데이터 Accuracy : 0.9963  \n",
    "테스트 데이터 Accuracy : 0.9893"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "99.57점을 받을 줄 알았는데, 98.85로 시험점수가 소폭 하락, 이유는 위 MNIST 데이터셋 참고문헌을 보시면 학습용 데이터와 시험용 데이터의 손글씨 주인이 다른 것을 알 수 있음, 즉, 한 번도 본적이 없는 필체의 손글씨가 섞여 있을 가능성이 높으며, 어찌보면 인식률이 떨어지는 것은 어느 정도 예상 가능한 일"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 더 좋은 네트워크 만들어보기\n",
    "\n",
    "인식률 99점대를 목표로\n",
    "\n",
    "딥러닝 네트워크의 구조 자체는 바꾸지 않으면서도 우리가 해볼 수 있는 것들이 있는데, Step 3에서 살펴본 하이퍼파라미터들을 바꾸어 보는 것\n",
    "\n",
    "+ Conv2D 레이어에서 입력 이미지의 특징 수를 늘리거나 줄여 봄\n",
    "```\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,1)))\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "```\n",
    "+ Dense 레이어에서 뉴런수를 바꾸어 봄\n",
    "```\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "```\n",
    "+ 학습 반복 횟수인 epoch 값을 변경\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 30,762\n",
      "Trainable params: 30,762\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1870 - accuracy: 0.9437\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0604 - accuracy: 0.9812\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0452 - accuracy: 0.9857\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0353 - accuracy: 0.9889\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0281 - accuracy: 0.9911\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0245 - accuracy: 0.9919\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0190 - accuracy: 0.9940\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0166 - accuracy: 0.9947\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0143 - accuracy: 0.9953\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0123 - accuracy: 0.9961\n",
      "313/313 - 0s - loss: 0.0317 - accuracy: 0.9900\n",
      "test_loss: 0.03169659525156021 \n",
      "test_accuracy: 0.9900000095367432\n"
     ]
    }
   ],
   "source": [
    "#바꿔 볼 수 있는 하이퍼파라미터들\n",
    "n_channel_1=16\n",
    "n_channel_2=32\n",
    "n_dense=32\n",
    "n_train_epoch=10\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,1)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train_reshaped, y_train, epochs=n_train_epoch)\n",
    "\n",
    "# 모델 시험\n",
    "test_loss, test_accuracy = model.evaluate(x_test_reshaped, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_epoch : 10\n",
    "\n",
    "313/313 - 0s - loss: 0.0317 - accuracy: 0.9900  \n",
    "test_loss: 0.03169659525156021  \n",
    "test_accuracy: 0.9900000095367432"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 회고\n",
    "---\n",
    "+ 프로젝트에서 어려웠던 점\n",
    "+ 프로젝트를 진행하면서 알아낸 점, 아직 모호한 점\n",
    "+ 루브릭 평가 지표를 맞추기 위해 시도한 것들\n",
    "+ 만약에 루브릭 평가 관련 지표를 달성하지 못했을 때, 이유에 관한 추정\n",
    "+ 자기 다짐\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 프로젝트에서 어려웠던 점\n",
    "---\n",
    "\n",
    "+ 처음 딥러닝 모델을 적용시키면서, tf.keras API가 익숙하지 않았던 점\n",
    "+ Sequential 모델이 정확히 모르고 진행했던 점"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 프로젝트를 진행하면서 알아낸 점, 아직 모호한 점\n",
    "---\n",
    "\n",
    "+ Q. 딥러닝 네트워크 설계 : 왜 네트워크 설계라고 하는 건지?\n",
    "+ Q : 인공지능 모델을 훈련시키고 사용할 때, 왜 0~1 사이의 값으로 정규화 시켜주는 것이 좋은지?\n",
    "+ Q. MaxPool2D와 MaxPooling2D의 차이점은?\n",
    "+ Q. activation = 'relu', 'softmax' 이건 뭔지? 그리고 다른 activation들은 어떤 것들이 있는지?\n",
    "+ Q. 알파벳 분류기의 경우, 왜 분류기에 사용되는 뉴런의 숫자로 52가 아닌 32, 64, 128 등을 고려하는 건지?\n",
    "+ Q. 같은 데이터셋을 가지고 동일하게 실행했는데도 Epoch별로 Accuracy가 달라지는 이유는 뭔지?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 루브릭 평가 지표를 맞추기 위해 시도한 것들\n",
    "---\n",
    "\n",
    "+ 하이퍼파라미터 변경 (2배수 증가)\n",
    "```\n",
    "#네트워크 모델 코드 : 하이퍼파라미터들 변경 (주로 초기 세팅된 값들보다 높게 설정, 2배 높게 설정하여 진행)\n",
    "#바꿔 볼 수 있는 하이퍼파라미터들\n",
    "n_channel_1=32\n",
    "n_channel_2=64\n",
    "n_dense=64\n",
    "n_train_epoch=20\n",
    "```\n",
    "+ 학습용 데이터 증가시켜 모델 학습 (300개 > 3000개, 10배 증가)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 만약에 루브릭 평가 관련 지표를 달성하지 못했을 때, 이유에 관한 추정\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 자기 다짐\n",
    "---\n",
    "\n",
    "+ 아직 딥러닝 관련해서 이해 못 한 부분들이 많긴 하지만, 계속 하다보면 익숙해지고 이해할 수 있을 거라고 생각하면서, 조바심 내기 보다는 여유를 가지고 고고고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
